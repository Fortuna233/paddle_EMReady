{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load data\n",
    "根据原论文内容，要：\n",
    "transform the .mrc file into np array\n",
    "chunked into pairs of overlapping boxes of size 60*60*60 with strides of 30 voxels\n",
    "augmentation:\n",
    "random 90 degree rotation\n",
    "randomly cropping 48*48*48 box from 60*60*60box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import mrcfile\n",
    "import numpy as np\n",
    "import interp_back\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from pytorch_msssim import ssim\n",
    "from scunet import SCUNet\n",
    "from utils import pad_map, chunk_generator, parse_map, get_batch_from_generator\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "depoFolder = \"/home/tyche/training_and_validation_sets/depoFiles\"\n",
    "simuFolder = \"/home/tyche/training_and_validation_sets/simuFiles\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_files(directory):\n",
    "    file_list = list()\n",
    "    for file in os.listdir(directory):\n",
    "        file_list.append(f\"{directory}/{file}\")\n",
    "    return file_list\n",
    "\n",
    "\n",
    "depoList = get_all_files(depoFolder)\n",
    "simuList = get_all_files(simuFolder)\n",
    "depoList.sort()\n",
    "simuList.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrc2padded(mrcfile, apix):\n",
    "    map, origin, nxyz, voxel_size, nxyz_origin = parse_map(mrcfile, ignorestart=False, apix=apix)\n",
    "    print(f\"# Original map dimensions: {nxyz_origin}\")\n",
    "    nxyzstart = np.round(origin / voxel_size).astype(np.int64)\n",
    "    print(f\"# Map dimensions at {apix} Angstrom grid size: {nxyz}\")\n",
    "    padded_map = pad_map(map, 60, dtype=np.float32, padding=0.0)\n",
    "    maximum = np.percentile(map[map > 0], 99.999)\n",
    "    del map\n",
    "    return padded_map, maximum\n",
    "\n",
    "\n",
    "padded_map, maximum = mrc2padded(depoList[-1], 1.0)\n",
    "generator = chunk_generator(padded_map, maximum, 60, 30)\n",
    "positions, chunks = get_batch_from_generator(generator, 10, dtype=np.float32)\n",
    "chunks.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform(tensor, outsize=48):\n",
    "    N = tensor.shape[0]\n",
    "    axes_options=[(0,1), (1, 2), (0, 2)]\n",
    "    nx, ny, nz = tensor.shape[1:4]\n",
    "    newx, newy, newz = outsize, outsize, outsize\n",
    "    output = torch.zeros(N, 48, 48, 48, device=tensor.device)\n",
    "    for i in range(N):\n",
    "        k = random.choice([1, 2, 3]) \n",
    "        rotated = torch.rot90(tensor[i], k=k, dims=random.choice(axes_options))\n",
    "        startX = random.randint(0, nx-newx)\n",
    "        startY = random.randint(0, ny-newy)\n",
    "        startZ = random.randint(0, nz-newz)\n",
    "        cropped = rotated[startX:startX+outsize, startY:startY+outsize, startZ:startZ+outsize]\n",
    "        output[i] = cropped\n",
    "    del tensor\n",
    "    torch.cuda.empty_cache()\n",
    "    return output\n",
    "\n",
    "# 输入为torch张量batch_size*60*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = SCUNet(\n",
    "    in_nc=1,\n",
    "    config=[2,2,2,2,2,2,2],\n",
    "    dim=32,\n",
    "    drop_path_rate=0.0,\n",
    "    input_resolution=48,\n",
    "    head_dim=16,\n",
    "    window_size=3,\n",
    ")\n",
    "torch.cuda.empty_cache()\n",
    "net = net.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, Y):\n",
    "    smooth_L1 = nn.SmoothL1Loss()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = torch.optim.Adam(net.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 300\n",
    "net.train()\n",
    "loss_values = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for depoFile, simuFile in zip(depoList, simuList):\n",
    "        if(os.path.getsize(depoFile) > 1024 * 1024 * 512 or os.path.getsize(simuFile) > 1024 * 1024 * 512):\n",
    "            continue\n",
    "        train_loss = 0\n",
    "        depoPadded, depoMax = mrc2padded(depoFile, 1.0)\n",
    "        simuPadded, simuMax = mrc2padded(simuFile, 1.0)\n",
    "        depo_generator = chunk_generator(depoPadded, depoMax, 60, 30)\n",
    "        simu_generator = chunk_generator(simuPadded, simuMax, 60, 30)\n",
    "        while True:\n",
    "            _, depo_chunks = get_batch_from_generator(depo_generator, 32, dtype=np.float32)\n",
    "            _, simu_chunks = get_batch_from_generator(simu_generator, 32, dtype=np.float32)\n",
    "            if depo_chunks.shape != simu_chunks.shape:\n",
    "                continue\n",
    "            \n",
    "            if depo_chunks.shape[0] == 0:\n",
    "                break\n",
    "            depo_chunks = torch.from_numpy(depo_chunks)\n",
    "            simu_chunks = torch.from_numpy(simu_chunks)\n",
    "            depo_chunks = transform(depo_chunks)\n",
    "            simu_chunks = transform(simu_chunks)\n",
    "            l = loss(net(depo_chunks), simu_chunks)\n",
    "            trainer.zero_grad()\n",
    "            l.backward()\n",
    "            trainer.step()\n",
    "            train_loss += l\n",
    "        plt.plot(epoch, train_loss, 'ro', label='Train')\n",
    "        plt.pause(0.01)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "emready_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
